# 第一堂課
# 爬蟲一

---

# 套件介紹

----

### requests
對網路發送請求的套件，可以實作對網路post與get等等的Http協定的行為。

----

### BeautifulSoup
解析網頁工具，幾行的code便可讀取Html代碼，與提取的動作。

---

## 一、(前一堂課會教)基礎網頁認識

---

## 二、爬蟲與Web關係

----

### 網路如何運行?
- 瀏覽器請求伺服器
    - HTTP request
    - HTTP response

----

## 看圖　
![](https://i.imgur.com/OUL0Qev.png)

----

### HTTP method
- Get
    - 向伺服器請求資源 
- Post
    - 送訊息給伺服器

----

### <Response [200]>
```python=
import requests
a=requests.get('你需要爬的網址')#https://ilearn2.fcu.edu.tw/
print(a)
```

----

![](https://i.imgur.com/FFJRtOe.png)

----

我們把print(a)改成print(a.text)，就可以印出內容

![](https://i.imgur.com/RfoJg91.png)


---

### 認識 cookie 
- 為何把網頁關掉後，在打開它還是出現一樣的東西，而不用再輸入資料?。
- 因為cookie為 User 端的 憑證

----

### 如果還不懂嗎?
### 丟去問google
![](https://i.imgur.com/KNH0mW0.png)

---


## 三、Regular Expression

----

### 使用compile 會返回一個名為regex物件，前面加上r 使後面為原始字串，轉譯字元為反斜線\
```python=
import re
phone_number=re.compile(r'(\d\d\d\d)-(\d\d\d\d\d\d)')# 
mo=phone_number.search('My phone number is 0988-058238.')
mo.group()
```

----

### ?可作為可選擇性的比對:

```python=
import re
batRegex=re.compile(r'Bat(wo)?man')
mo1=batRegex.search("Batman")
mo1.group()
```

----

### 使用*比對符合零次或多次
```python=
import re
batRegex=re.compile(r'Bat(wo)*man')
mo1=batRegex.search("Batwowowowowoman")
mo1.group()
```

----

### 使用{}比對符合次數:
```python=
import re
Regex=re.compile(r'(Ha){3}')
mo1=Regex.search("HaHaHa")
mo1.group()
```

----

### 使用+比對符合一次或多次

---

### 字元分類

----

- \d:0~9
- \D:0~9以外
- \w:任意字母數字底線字元
- \W:除了字母數字底線字元
- \s:空格、定位符號、換行符號(比對空白字元)
- \S:除了空格、定位符號、換行符號
- /[0-5]:比對0~5 請忽略/


----

## [正則_補充資料](https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonre/index.html)
## [正則_補充](http://www.runoob.com/regexp/regexp-syntax.html)

---



## 四、如何讀寫資料夾

----

![](https://i.imgur.com/N8ku75G.png)

----

### 創建檔案
```python=
f=open('test.txt','w')
f.write('hello word!!!!!!!!!\n')
f.close()
```

----

### 讀檔案
```python=
f=open('test.txt','r')
print(f.read())
```

----

### 寫檔+讀檔
```python=
f=open('test.txt','r+')
f.write('123333')
print(f.read())
```

---

## 五、實戰

----

## 必須知道的小知識

----

### find() 只找一筆資料

### find_all() 是找全部的

----

### find_all("標籤名稱") 

### find_all("class_=class的名稱")

### 因為class是保留字所以加上_

----

### 那我們開始爬Dcard的標題吧~!

----

```python=
from bs4 import BeautifulSoup
import requests
page = requests.get('https://www.dcard.tw/f')

##以BeautifulSoup解析 HTML 程式碼
data = BeautifulSoup(page.text, "html.parser")

print(data)
```

----

可以看到噴出來是解析過後，比較能看懂的內容，再來我們尋找要爬的標題放在哪裡?
打開f12

![](https://i.imgur.com/8CvQpN2.png)

----

發現標題都放在class=Title__Text-v196i6-0 gmfDU
![](https://i.imgur.com/YHZZQY4.png)

----

使用剛剛所教的find_all("class_=class的名稱")
然後使用迴圈印出它

----

完整code

```python=
from bs4 import BeautifulSoup
import requests
page = requests.get('https://www.dcard.tw/f')

data = BeautifulSoup(page.text, "html.parser")
title = data.find_all(class_="Title__Text-v196i6-0 gmfDU")

for i in title:
    print(i.text)

```

----

結果
![](https://i.imgur.com/8RIaD7V.png)

---

## 補充

----

### select 用法
```python=

資料.select("div")#選取div的資料
資料.select("div.class的名稱")#選取div底下指定class的資料
資料.select("#id")#選取唯一id的資料，html中id都是唯一的
資料.select("標籤")#選取標籤，例如"a"
資料.select("標籤 > 標籤") # 選取標籤底下的東西
```

----

那我們使用select爬取

----

```python=
from bs4 import BeautifulSoup
import requests
page = requests.get('https://www.dcard.tw/f')

data = BeautifulSoup(page.text, "html.parser")

title = data.select("div > h3")

for i in title:
    print(i.text)
```

----

結果
![](https://i.imgur.com/y0XzLtc.png)

